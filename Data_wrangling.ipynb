{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1137a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a3a86d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/jwu/Documents/5400/data/cvxEDA-master/src') #modify abs path to your /src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "163148e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install cvxopt\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import scipy.signal as scisig\n",
    "import scipy.stats\n",
    "import cvxEDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "801439d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E4 (wrist) Sampling Frequencies\n",
    "fs_dict = {'ACC': 32, 'BVP': 64, 'EDA': 4, 'TEMP': 4, 'label': 700, 'Resp': 700}\n",
    "WINDOW_IN_SECONDS = 30\n",
    "label_dict = {'baseline': 1, 'stress': 2, 'amusement': 0}\n",
    "int_to_label = {1: 'baseline', 2: 'stress', 0: 'amusement'}\n",
    "feat_names = None\n",
    "savePath = 'data'\n",
    "subject_feature_path = '/subject_feats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26ecd23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether path exists\n",
    "def ensure_directory_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "ensure_directory_exists(savePath)\n",
    "\n",
    "full_subject_path = os.path.join(savePath, subject_feature_path.strip('/'))\n",
    "ensure_directory_exists(full_subject_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a4b9637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes the EDA\n",
    "def eda_stats(y):\n",
    "    Fs = fs_dict['EDA']\n",
    "    y_norm = (y - y.mean()) / y.std()\n",
    "    [r, p, t, l, d, e, obj] = cvxEDA.cvxEDA(y_norm, 1. / Fs)\n",
    "    return [r, p, t, l, d, e, obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbc5fcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main class that creates attributes and access each survey to extract info\n",
    "class SubjectData:\n",
    "    def __init__(self, main_path, subject_number):\n",
    "        self.name = f'S{subject_number}'\n",
    "        self.subject_keys = ['signal', 'label', 'subject']\n",
    "        self.signal_keys = ['chest', 'wrist']\n",
    "        self.chest_keys = ['ACC', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp']\n",
    "        self.wrist_keys = ['ACC', 'BVP', 'EDA', 'TEMP']\n",
    "        file_path = os.path.join(main_path, self.name, f'{self.name}.pkl')\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'rb') as file:\n",
    "                self.data = pickle.load(file, encoding='latin1')\n",
    "            self.labels = self.data.get('label', [])\n",
    "        except FileNotFoundError:\n",
    "            self.data = {}  \n",
    "            print(f\"Data file not found: {file_path}\")\n",
    "        except Exception as e:\n",
    "            self.data = {}  \n",
    "            print(f\"An error occurred while loading the data: {str(e)}\")\n",
    "\n",
    "    def get_wrist_data(self):\n",
    "        try:\n",
    "            wrist_data = self.data['signal']['wrist'].copy()  \n",
    "            wrist_data['Resp'] = self.data['signal']['chest']['Resp']  \n",
    "            return wrist_data\n",
    "        except KeyError as e:\n",
    "            print(f\"Key error accessing wrist/chest data: {str(e)}\")\n",
    "            return {}  \n",
    "\n",
    "    def get_chest_data(self):\n",
    "        return self.data.get('signal', {}).get('chest', {})  # Safe access with default empty dict\n",
    "\n",
    "    def extract_features(self):\n",
    "        results = {\n",
    "                key: get_statistics(self.get_wrist_data()[key].flatten(), self.labels, key)\n",
    "                for key in self.wrist_keys\n",
    "            }\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97883dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper methods\n",
    "# https://github.com/MITMediaLabAffectiveComputing/eda-explorer/blob/master/load_files.py\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = scisig.butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    # Filtering Helper functions\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = scisig.lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def get_slope(series):\n",
    "    linreg = scipy.stats.linregress(np.arange(len(series)), series )\n",
    "    slope = linreg[0]\n",
    "    return slope\n",
    "\n",
    "def get_window_stats(data, label=-1):\n",
    "    mean_features = np.mean(data)\n",
    "    std_features = np.std(data)\n",
    "    min_features = np.amin(data)\n",
    "    max_features = np.amax(data)\n",
    "\n",
    "    features = {'mean': mean_features, 'std': std_features, 'min': min_features, 'max': max_features,\n",
    "                'label': label}\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_net_accel(data):\n",
    "    return (data['ACC_x'] ** 2 + data['ACC_y'] ** 2 + data['ACC_z'] ** 2).apply(lambda x: np.sqrt(x))\n",
    "\n",
    "\n",
    "def get_peak_freq(x):\n",
    "    f, Pxx = scisig.periodogram(x, fs=8)\n",
    "    psd_dict = {amp: freq for amp, freq in zip(Pxx, f)}\n",
    "    peak_freq = psd_dict[max(psd_dict.keys())]\n",
    "    return peak_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f302d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acc feature extraction\n",
    "# https://github.com/MITMediaLabAffectiveComputing/eda-explorer/blob/master/AccelerometerFeatureExtractionScript.py\n",
    "def filterSignalFIR(eda, cutoff=0.4, numtaps=64):\n",
    "    f = cutoff / (fs_dict['ACC'] / 2.0)\n",
    "    FIR_coeff = scisig.firwin(numtaps, f)\n",
    "\n",
    "    return scisig.lfilter(FIR_coeff, 1, eda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1160bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(e4_data_dict, labels, norm_type=None):\n",
    "    # Dataframes for each sensor type\n",
    "    eda_df = pd.DataFrame(e4_data_dict['EDA'], columns=['EDA'])\n",
    "    bvp_df = pd.DataFrame(e4_data_dict['BVP'], columns=['BVP'])\n",
    "    acc_df = pd.DataFrame(e4_data_dict['ACC'], columns=['ACC_x', 'ACC_y', 'ACC_z'])\n",
    "    temp_df = pd.DataFrame(e4_data_dict['TEMP'], columns=['TEMP'])\n",
    "    label_df = pd.DataFrame(labels, columns=['label'])\n",
    "    resp_df = pd.DataFrame(e4_data_dict['Resp'], columns=['Resp'])\n",
    "\n",
    "    # Filter EDA\n",
    "    eda_df['EDA'] = butter_lowpass_filter(eda_df['EDA'], 1.0, fs_dict['EDA'], 6)\n",
    "\n",
    "    # Filter ACM\n",
    "    for _ in acc_df.columns:\n",
    "        acc_df[_] = filterSignalFIR(acc_df.values)\n",
    "\n",
    "    # Adding indices for combination due to differing sampling frequencies\n",
    "    eda_df.index = [(1 / fs_dict['EDA']) * i for i in range(len(eda_df))]\n",
    "    bvp_df.index = [(1 / fs_dict['BVP']) * i for i in range(len(bvp_df))]\n",
    "    acc_df.index = [(1 / fs_dict['ACC']) * i for i in range(len(acc_df))]\n",
    "    temp_df.index = [(1 / fs_dict['TEMP']) * i for i in range(len(temp_df))]\n",
    "    label_df.index = [(1 / fs_dict['label']) * i for i in range(len(label_df))]\n",
    "    resp_df.index = [(1 / fs_dict['Resp']) * i for i in range(len(resp_df))]\n",
    "\n",
    "    # Change indices to datetime\n",
    "    eda_df.index = pd.to_datetime(eda_df.index, unit='s')\n",
    "    bvp_df.index = pd.to_datetime(bvp_df.index, unit='s')\n",
    "    temp_df.index = pd.to_datetime(temp_df.index, unit='s')\n",
    "    acc_df.index = pd.to_datetime(acc_df.index, unit='s')\n",
    "    label_df.index = pd.to_datetime(label_df.index, unit='s')\n",
    "    resp_df.index = pd.to_datetime(resp_df.index, unit='s')\n",
    "\n",
    "    # New EDA features\n",
    "    r, p, t, l, d, e, obj = eda_stats(eda_df['EDA'])\n",
    "    eda_df['EDA_phasic'] = r\n",
    "    eda_df['EDA_smna'] = p\n",
    "    eda_df['EDA_tonic'] = t\n",
    "        \n",
    "    # Combined dataframe - not used yet\n",
    "    df = eda_df.join(bvp_df, how='outer')\n",
    "    df = df.join(temp_df, how='outer')\n",
    "    df = df.join(acc_df, how='outer')\n",
    "    df = df.join(resp_df, how='outer')\n",
    "    df = df.join(label_df, how='outer')\n",
    "    df['label'] = df['label'].fillna(method='bfill')\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    if norm_type is 'std':\n",
    "        # std norm\n",
    "        df = (df - df.mean()) / df.std()\n",
    "    elif norm_type is 'minmax':\n",
    "        # minmax norm\n",
    "        df = (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "    # Groupby\n",
    "    grouped = df.groupby('label')\n",
    "    baseline = grouped.get_group(1)\n",
    "    stress = grouped.get_group(2)\n",
    "    amusement = grouped.get_group(3)\n",
    "    return grouped, baseline, stress, amusement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9f51814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function gets each features and labels\n",
    "def get_samples(data, n_windows, label):\n",
    "    global feat_names\n",
    "    global WINDOW_IN_SECONDS\n",
    "\n",
    "    samples = []\n",
    "    window_len = fs_dict['label'] * WINDOW_IN_SECONDS\n",
    "\n",
    "    for i in range(n_windows):\n",
    "\n",
    "        w = data[window_len * i: window_len * (i + 1)]\n",
    "\n",
    "        net_acc = get_net_accel(w[['ACC_x', 'ACC_y', 'ACC_z']])\n",
    "        w = pd.concat([w, net_acc.rename('net_acc')], axis=1)\n",
    "\n",
    "        wstats = get_window_stats(data=w, label=label)\n",
    "\n",
    "        x = pd.DataFrame(wstats).drop('label', axis=0)\n",
    "        y = wstats['label']\n",
    "\n",
    "        if feat_names is None or len(feat_names) != len(x.columns):\n",
    "            feat_names = [f'{str(row)}_{str(col)}' for row in x.index for col in x.columns]\n",
    "\n",
    "        wdf = pd.DataFrame(x.values.flatten()).T\n",
    "        wdf.columns = feat_names\n",
    "        wdf['label'] = y\n",
    "\n",
    "        wdf['BVP_peak_freq'] = get_peak_freq(w['BVP'].dropna())\n",
    "        wdf['TEMP_slope'] = get_slope(w['TEMP'].dropna())\n",
    "\n",
    "        samples.append(wdf)\n",
    "\n",
    "    return pd.concat(samples) if samples else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d59109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function gets the data from each survey\n",
    "def make_patient_data(subject_id):\n",
    "    global savePath\n",
    "    global WINDOW_IN_SECONDS\n",
    "\n",
    "    subject = SubjectData(main_path='data/WESAD', subject_number=subject_id)\n",
    "\n",
    "    e4_data_dict = subject.get_wrist_data()\n",
    "\n",
    "    # norm type\n",
    "    norm_type = None\n",
    "\n",
    "    grouped, baseline, stress, amusement = compute_features(e4_data_dict, subject.labels, norm_type)\n",
    "\n",
    "    n_baseline_wdws = int(len(baseline) / (fs_dict['label'] * WINDOW_IN_SECONDS))\n",
    "    n_stress_wdws = int(len(stress) / (fs_dict['label'] * WINDOW_IN_SECONDS))\n",
    "    n_amusement_wdws = int(len(amusement) / (fs_dict['label'] * WINDOW_IN_SECONDS))\n",
    "    baseline_samples = get_samples(baseline, n_baseline_wdws, 1)\n",
    "    stress_samples = get_samples(stress, n_stress_wdws, 2)\n",
    "    amusement_samples = get_samples(amusement, n_amusement_wdws, 0)\n",
    "\n",
    "    all_samples = pd.concat([baseline_samples, stress_samples, amusement_samples])\n",
    "    all_samples = pd.concat([all_samples.drop('label', axis=1), pd.get_dummies(all_samples['label'])], axis=1)\n",
    "    all_samples.to_csv(f'{savePath}{subject_feature_path}/S{subject_id}_feats_4.csv')\n",
    "\n",
    "    subject = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a854948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function combines paths to store the Sx_feats_4.csv\n",
    "def combine_files(subjects):\n",
    "    df_list = []\n",
    "    for subject_id in subjects:\n",
    "        file_path = os.path.join(savePath, subject_feature_path, f'S{subject_id}_feats_4.csv')\n",
    "        df = pd.read_csv(file_path, index_col=0)\n",
    "        df['subject'] = subject_id\n",
    "        df_list.append(df)\n",
    "\n",
    "    combined_df = pd.concat(df_list)\n",
    "    combined_df = transform_labels_to_single_column(combined_df)\n",
    "    save_combined_data(combined_df)\n",
    "\n",
    "# Transforms multi-column labels into a single column\n",
    "def transform_labels_to_single_column(df):\n",
    "    label_cols = ['0', '1', '2']\n",
    "    df['label'] = df[label_cols].astype(str).apply(lambda row: ''.join(row), axis=1).apply(lambda x: x.index('1'))\n",
    "    df.drop(label_cols, axis=1, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Save the combined file as may14_feats4.csv\n",
    "def save_combined_data(df):\n",
    "    output_file = os.path.join(savePath, 'may14_feats4.csv')\n",
    "    df.to_csv(output_file)\n",
    "    print(f'Saved combined data to {output_file}')\n",
    "    \n",
    "    display_sample_counts(df['label'])\n",
    "\n",
    "# This function displays sample counts by print out each label and corresponding counts\n",
    "def display_sample_counts(labels):\n",
    "    counts = labels.value_counts()\n",
    "    print('Number of samples per class:')\n",
    "    for label, number in counts.items():\n",
    "        label_name = int_to_label.get(label, f'Label {label}')\n",
    "        print(f'{label_name}: {number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b675ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Convert and extract survey 2-11 features\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "\n",
    "    for patient in subject_ids:\n",
    "        print(f'Processing data for S{patient}...')\n",
    "        make_patient_data(patient)\n",
    "\n",
    "    combine_files(subject_ids)\n",
    "    print('Processing complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99aff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFERENCES:\n",
    "# [1] Schmidt, Philip & Reiss, Attila & Duerichen, Robert & Marberger, Claus & Van Laerhoven, Kristof. (2018). Introducing WESAD, a Multimodal Dataset for Wearable Stress and Affect Detection. 400-408. 10.1145/3242969.3242985.  https://dl.acm.org/citation.cfm?doid=3242969.3242985\n",
    "\n",
    "# [2] A Greco, G Valenza, A Lanata, EP Scilingo, and L Citi \"cvxEDA: a Convex Optimization Approach to Electrodermal Activity Processing\", IEEE Transactions on Biomedical Engineering, 2015DOI: 10.1109/TBME.2015.2474131, https://github.com/lciti/cvxEDA\n",
    "\n",
    "# [3] Schmidt, P., Reiss, A., Duerichen, R., Marberger, C., Van Laerhoven, K., & WJMatthew. (Year). WESAD: A publicly available dataset for wearable stress and affect detection. GitHub. https://github.com/WJMatthew/WESAD\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
